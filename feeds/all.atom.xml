<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>hella labs</title><link href="https://www.qrk.us/" rel="alternate"></link><link href="https://www.qrk.us/feeds/all.atom.xml" rel="self"></link><id>https://www.qrk.us/</id><updated>2023-09-23T21:37:10-04:00</updated><entry><title>CloudFlare DNS for Network Manager</title><link href="https://www.qrk.us/cloudflare-dns-for-network-manager.html" rel="alternate"></link><published>2023-09-23T21:37:10-04:00</published><updated>2023-09-23T21:37:10-04:00</updated><author><name>Ken</name></author><id>tag:www.qrk.us,2023-09-23:/cloudflare-dns-for-network-manager.html</id><summary type="html">&lt;p&gt;CloudFlare provides &lt;a href="https://developers.cloudflare.com/1.1.1.1/what-is-1.1.1.1/"&gt;a performant recursive nameserver&lt;/a&gt; along with a promise to never surveil their users.&lt;/p&gt;
&lt;p&gt;Their Linux quickstart involves modifying the standard C library's resolver (i.e. /etc/resolv.conf) which is a terrible idea if you are using most of the popular flavors of Linux as a daily driver …&lt;/p&gt;</summary><content type="html">&lt;p&gt;CloudFlare provides &lt;a href="https://developers.cloudflare.com/1.1.1.1/what-is-1.1.1.1/"&gt;a performant recursive nameserver&lt;/a&gt; along with a promise to never surveil their users.&lt;/p&gt;
&lt;p&gt;Their Linux quickstart involves modifying the standard C library's resolver (i.e. /etc/resolv.conf) which is a terrible idea if you are using most of the popular flavors of Linux as a daily driver desktop OS because they're likely using &lt;code&gt;dnsmasq&lt;/code&gt; or &lt;code&gt;resolvconf&lt;/code&gt; or both to declare the contents of that file.&lt;/p&gt;
&lt;p&gt;For what it's worth, here's shellcode to quickly reconfigure an existing Network Manager saved connection with &lt;code&gt;nmcli&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# make a note of the name of the connection you wish to configure e.g. &amp;quot;WiFi Secure&amp;quot;&lt;/span&gt;
nmcli&lt;span class="w"&gt; &lt;/span&gt;connection&lt;span class="w"&gt; &lt;/span&gt;show

&lt;span class="c1"&gt;# save the name of the connection in a variable&lt;/span&gt;
&lt;span class="nb"&gt;export&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;CONN&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;WiFi Secure&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# paste the following in your terminal to reconfigure DNS&lt;/span&gt;
nmcli&lt;span class="w"&gt; &lt;/span&gt;connection&lt;span class="w"&gt; &lt;/span&gt;modify&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$CONN&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;ipv4.ignore-auto-dns&lt;span class="w"&gt; &lt;/span&gt;yes&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;ipv4.never-default&lt;span class="w"&gt; &lt;/span&gt;no&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;ipv4.dns&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;1.1.1.1&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# reactivate the saved connection&lt;/span&gt;
nmcli&lt;span class="w"&gt; &lt;/span&gt;connection&lt;span class="w"&gt; &lt;/span&gt;up&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$CONN&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# optionally restore default DNS (DHCP)&lt;/span&gt;
nmcli&lt;span class="w"&gt; &lt;/span&gt;connection&lt;span class="w"&gt; &lt;/span&gt;modify&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$CONN&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;ipv4.ignore-auto-dns&lt;span class="w"&gt; &lt;/span&gt;no
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="tech"></category><category term="Linux"></category><category term="dns"></category><category term="sysadmin"></category><category term="network manager"></category></entry><entry><title>Fly.io Programmable Front-end</title><link href="https://www.qrk.us/flyio-programmable-front-end.html" rel="alternate"></link><published>2023-09-23T21:37:10-04:00</published><updated>2023-09-23T21:37:10-04:00</updated><author><name>Ken</name></author><id>tag:www.qrk.us,2023-09-23:/flyio-programmable-front-end.html</id><summary type="html">&lt;p&gt;In short, a programmable cloud delivery network (CDN) aka front-end like Fly.io is an API by which to configure the logical edge of an application stack. Fly.io also provides an intuitive web UI which simplifies common administrative operations.&lt;/p&gt;
&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#example-of-a-multi-cloud-backend-fronted-by-flyio"&gt;Example of a multi-cloud backend fronted by …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;In short, a programmable cloud delivery network (CDN) aka front-end like Fly.io is an API by which to configure the logical edge of an application stack. Fly.io also provides an intuitive web UI which simplifies common administrative operations.&lt;/p&gt;
&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#example-of-a-multi-cloud-backend-fronted-by-flyio"&gt;Example of a multi-cloud backend fronted by Fly.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#example-of-a-personal-web-site-without-hosting-expenses"&gt;Example of a personal web site without hosting expenses&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;high availability for a service endpoint (this is automatic);&lt;/li&gt;
&lt;li&gt;requesting, issuing, binding, and renewing a free TLS server certificate (just verify a domain name);&lt;/li&gt;
&lt;li&gt;injecting business logic and automation at the application edge e.g. analytics, policies, authentication, caching, redirects, lambda functions, etc... (just click to enable middleware); and&lt;/li&gt;
&lt;li&gt;allocating workloads to multiple upstreams (backend capacity pools e.g. GCE, ECS, EC2).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="example-of-a-multi-cloud-backend-fronted-by-flyio"&gt;Example of a multi-cloud backend fronted by Fly.io&lt;/h3&gt;
&lt;p&gt;For one project I created a Fly.io "site" to front an application served up by Kubernetes in Google Compute Engine (GCE) and Elastic Container Service (ECS) simultaneously. Such a multi-cloud architecture is typically possible with any CDN, but here's an overview of the steps to do this with Fly.io.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;docker push&lt;/code&gt; to upload my custom Docker image to the Elastic Container Registry (ECR)&lt;/li&gt;
&lt;li&gt;configure the Kubernetes cluster to source that container image by registry address, name:tag, and publish the service port on a load balancer&lt;/li&gt;
&lt;li&gt;configure AWS's ECS Fargate to source the image by name:tag (requires hosting the container image in ECR), and publish the service port on an Elastic Load Balancer (ELB)&lt;/li&gt;
&lt;li&gt;create the Fly.io site with a backend of the Kubernetes load balancer address:port and ELB address:port&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A note about TLS (SSL): It's a great idea to require TLS everywhere. This gives greater assurance of data integrity even when confidentiality is a non-issue. Both GCE Kubernetes LBs and ELBs can issue and bind a free TLS server certificate. There's no need to request a certificate common name (CN) or subject alternative name (SAN) matching the domain name your clients/customers will "see". This is because the frontend provided by Fly.io will bind that familiar domain name when you verify the DNS hostname. The CN+SAN in the backend load balancers' server certificates are arbitrary and simply need to match the domain name generated by that platform for the particular service address e.g. example-service-2045107736.us-east-1.elb.amazonaws.com.&lt;/p&gt;
&lt;h2 id="example-of-a-personal-web-site-without-hosting-expenses"&gt;Example of a personal web site without hosting expenses&lt;/h2&gt;
&lt;p&gt;I came across Fly.io by way of an email invitation for a free trial and have combined this with &lt;a href="https://www.qrk.us/keybase.html"&gt;the Keybase Filesystem&lt;/a&gt; and the Pelican static HTML generator (described in &lt;a href="https://www.qrk.us/pages/about.html"&gt;About page&lt;/a&gt;) to create this blog site which is highly secure, performant, highly available, and (for now) completely free of operational expenses!&lt;/p&gt;
&lt;hr&gt;</content><category term="tech"></category><category term="cdn"></category><category term="devops"></category></entry><entry><title>How I Reclaimed Storage Space in Google Photos By Moving All My Videos</title><link href="https://www.qrk.us/how-i-reclaimed-storage-space-in-google-photos-by-moving-all-my-videos.html" rel="alternate"></link><published>2023-09-23T21:37:10-04:00</published><updated>2023-09-23T21:37:10-04:00</updated><author><name>Ken</name></author><id>tag:www.qrk.us,2023-09-23:/how-i-reclaimed-storage-space-in-google-photos-by-moving-all-my-videos.html</id><summary type="html">&lt;p&gt;There's no easy way to find and delete a particular file or type of file in Google Photos, and there's no way to bulk delete with a tool or even the API. Here's a simple tool chain that answered my need to move all videos out to reclaim storage space …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There's no easy way to find and delete a particular file or type of file in Google Photos, and there's no way to bulk delete with a tool or even the API. Here's a simple tool chain that answered my need to move all videos out to reclaim storage space.&lt;/p&gt;
&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#sync-photos-and-videos"&gt;Sync Photos and Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#move-videos"&gt;Move Videos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#delete-all-videos-from-google-photos"&gt;Delete All Videos From Google Photos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#replicated-videos-to-new-storage"&gt;Replicated Videos to New Storage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;Google Photos has some unique talents. I find it useful for exploring my own archives with the built-in machine learning features like "pictures from Ashland" or "red car". The balance of value is less favorable for videos, and they were the only reason I was paying for 2TB of cloud storage, so I decided to prune them out of my Google Photos account.&lt;/p&gt;
&lt;p&gt;Problem: there's no easy way to do that! Even the API doesn't have a delete operation. I can find them easily enough in the app by searching "videos", and I can painstakingly download them and delete them, but I'd prefer to express this as code, if possible.&lt;/p&gt;
&lt;h2 id="sync-photos-and-videos"&gt;Sync Photos and Videos&lt;/h2&gt;
&lt;p&gt;I found &lt;code&gt;gphotos-sync&lt;/code&gt;, a handy implementation of the Google Photos API that creates a local replica of the entire library with albums and other metadata that I didn't need. Still, supremely useful to make sure I have a copy of all videos.&lt;/p&gt;
&lt;h2 id="move-videos"&gt;Move Videos&lt;/h2&gt;
&lt;p&gt;I wrote a tiny Python program to to move my videos out of the gphotos-sync directory.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;walk the gphotos-sync photos directory&lt;/li&gt;
&lt;li&gt;detect if a file is a video MIME type&lt;/li&gt;
&lt;li&gt;move the videos to a new folder&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯&lt;span class="w"&gt; &lt;/span&gt;python&lt;span class="w"&gt; &lt;/span&gt;./move_videos.py
Moving:&lt;span class="w"&gt; &lt;/span&gt;./2017/02/2017-02-15-they-sang.mp4&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;787&lt;/span&gt;.8MiB&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;./Videos/videos_from_gphotos/2017/02/2017-02-15-they-sang.mp4
Moving:&lt;span class="w"&gt; &lt;/span&gt;./2003/04/or-portland-roofing_residence.3gp&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;849&lt;/span&gt;.1KiB&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;./Videos/videos_from_gphotos/2003/04/or-portland-roofing_residence.3gp
Moving:&lt;span class="w"&gt; &lt;/span&gt;./2003/02/or-ashland-alex_and_ax_blowin_in_the_wind.3gp&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.0MiB&lt;span class="w"&gt; &lt;/span&gt;-&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;./Videos/videos_from_gphotos/1973/02/or-ashland-alex_and_ax_blowin_in_the_wind.3gp
Total:&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;58&lt;/span&gt;.7GiB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;filetype&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;os.path&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;getsize&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dirname&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;walk&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;chdir&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;shutil&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;move&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;

&lt;span class="c1"&gt;# move_videos.py moves files with a video MIME type to a different top-level directory with the same directory structure&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="c1"&gt;# The top argument for walk&lt;/span&gt;
    &lt;span class="n"&gt;topdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;./Downloads/from_gphotos/photos&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;dest_topdir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;./Videos/videos_from_gphotos&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;chdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;topdir&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;total_bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dirs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;walk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_symlink&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
                &lt;span class="k"&gt;continue&lt;/span&gt;
            &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;filetype&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_video&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
                &lt;span class="n"&gt;size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getsize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="n"&gt;total_bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;total_bytes&lt;/span&gt;
                &lt;span class="n"&gt;dest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dest_topdir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;./&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Moving:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;sizeof_fmt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;-&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;parent&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dirname&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                    &lt;span class="n"&gt;parent&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkdir&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;parents&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;exist_ok&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;move&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dest&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;raise&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;pass&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Total:&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sizeof_fmt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total_bytes&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;sizeof_fmt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;suffix&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;B&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;unit&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Ki&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Mi&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Gi&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Ti&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Pi&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Ei&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Zi&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;3.1f&lt;/span&gt;&lt;span class="si"&gt;}{&lt;/span&gt;&lt;span class="n"&gt;unit&lt;/span&gt;&lt;span class="si"&gt;}{&lt;/span&gt;&lt;span class="n"&gt;suffix&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;num&lt;/span&gt; &lt;span class="o"&gt;/=&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;num&lt;/span&gt;&lt;span class="si"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;.1f&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;Yi&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;suffix&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id="delete-all-videos-from-google-photos"&gt;Delete All Videos From Google Photos&lt;/h2&gt;
&lt;p&gt;There's a simple trick to do this in a fell swoop.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;search "videos" and make sure the results are all videos&lt;/li&gt;
&lt;li&gt;tick the select box on the first result&lt;/li&gt;
&lt;li&gt;scroll down to the bottom of results&lt;/li&gt;
&lt;li&gt;hold SHIFT and left-click the last result&lt;/li&gt;
&lt;li&gt;click the trash button or press &lt;code&gt;#&lt;/code&gt; to delete&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As of this writing the videos would be in Trash for 60 days before they're permanently deleted and the available storage returned to you.&lt;/p&gt;
&lt;h2 id="replicated-videos-to-new-storage"&gt;Replicated Videos to New Storage&lt;/h2&gt;
&lt;p&gt;I still need to keep a copy of my videos off-site in case something happens to my storage at home or I lose access for some reason. I didn't want to keep track of copying the files so it needs to be an automated sync.&lt;/p&gt;
&lt;p&gt;I chose &lt;code&gt;rclone&lt;/code&gt; which is a versatile sync tool for cloud storage. It works with S3-compliant APIs, and I found STORJ has a very cheap option and as a bonus it is a form decentralized storage with an open-source bent. Cool.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;I signed up for Storj's free 150GB option and added about 20 USD worth of STORJ tokens to my account to cover future overages. No credit card required. &lt;/li&gt;
&lt;li&gt;I followed &lt;a href="https://docs.storj.io/dcs/how-tos/sync-files-with-rclone/rclone-with-native-integration/"&gt;Storj's own guide&lt;/a&gt; for configuring &lt;code&gt;rclone&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;I added a sync command to my backup script:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;rclone&lt;span class="w"&gt; &lt;/span&gt;sync&lt;span class="w"&gt; &lt;/span&gt;~/Videos/&lt;span class="w"&gt; &lt;/span&gt;storj:videos/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="tech"></category><category term="python"></category><category term="backup"></category><category term="rclone"></category></entry><entry><title>Keybase</title><link href="https://www.qrk.us/keybase.html" rel="alternate"></link><published>2023-09-23T21:37:10-04:00</published><updated>2023-09-23T21:37:10-04:00</updated><author><name>Ken</name></author><id>tag:www.qrk.us,2023-09-23:/keybase.html</id><summary type="html">&lt;p&gt;I first started using &lt;a href="https://www.keybase.io"&gt;@KeybaseIO&lt;/a&gt; a few years ago to link together my social accounts. This creates a web of accounts which is dramatically more difficult to impersonate than any single account. So, it's an exercise in impeding identity theft.&lt;/p&gt;
&lt;p&gt;A web of accounts could, for example, enable me to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I first started using &lt;a href="https://www.keybase.io"&gt;@KeybaseIO&lt;/a&gt; a few years ago to link together my social accounts. This creates a web of accounts which is dramatically more difficult to impersonate than any single account. So, it's an exercise in impeding identity theft.&lt;/p&gt;
&lt;p&gt;A web of accounts could, for example, enable me to trust your email signature when I only know you through Twitter.&lt;/p&gt;
&lt;p&gt;The Keybase filesystem is one of the newer tools and has a lot of promise. It is a global
namespace with public and private trees. The private tree allows any two parties have a
truly confidential exchange of data just by reading and writing in the special folders on
their computer. You can look over here for &lt;a href="https://keybase.io/docs/kbfs"&gt;more info about
it&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This web page is actually hosted in the kbfs at &lt;code&gt;/keybase/public/kourier&lt;/code&gt;. The content is
signed during upload and so is verifiable by running the Keybase app on your computer,
though it is not obvious in your web browser.&lt;/p&gt;
&lt;p&gt;If you install Keybase you'll be able to passively track changes in the web of identity
with commands like&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;keybase&lt;span class="w"&gt; &lt;/span&gt;follow&lt;span class="w"&gt; &lt;/span&gt;kourier
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;hr&gt;</content><category term="tech"></category><category term="identity"></category><category term="encryption"></category></entry><entry><title>Securing AWS Credentials</title><link href="https://www.qrk.us/securing-aws-credentials.html" rel="alternate"></link><published>2023-09-23T21:37:10-04:00</published><updated>2023-09-23T21:37:10-04:00</updated><author><name>Ken</name></author><id>tag:www.qrk.us,2023-09-23:/securing-aws-credentials.html</id><summary type="html">&lt;p&gt;A single &lt;a href="https://github.com/joho/aws-pony"&gt;rogue npm module&lt;/a&gt;, Ruby gem, PyPi module, or ill-fated cURL command could expose you (and your employer) to extreme risk.&lt;/p&gt;
&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#is-this-you"&gt;Is this you?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#the-problem"&gt;The Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#a-solution"&gt;A Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#do-it-yourself"&gt;Do it Yourself&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#shortcuts"&gt;Shortcuts&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#enable-privileges"&gt;Enable Privileges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#disable-privileges"&gt;Disable Privileges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#assume-role"&gt;Assume Role&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#related"&gt;Related&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="is-this-you"&gt;Is this you?&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# ~/.aws/credentials&lt;/span&gt;
&lt;span class="k"&gt;[default]&lt;/span&gt;
&lt;span class="na"&gt;aws_access_key_id …&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;A single &lt;a href="https://github.com/joho/aws-pony"&gt;rogue npm module&lt;/a&gt;, Ruby gem, PyPi module, or ill-fated cURL command could expose you (and your employer) to extreme risk.&lt;/p&gt;
&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#is-this-you"&gt;Is this you?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#the-problem"&gt;The Problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#a-solution"&gt;A Solution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#do-it-yourself"&gt;Do it Yourself&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#shortcuts"&gt;Shortcuts&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#enable-privileges"&gt;Enable Privileges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#disable-privileges"&gt;Disable Privileges&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#assume-role"&gt;Assume Role&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#related"&gt;Related&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;h2 id="is-this-you"&gt;Is this you?&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# ~/.aws/credentials&lt;/span&gt;
&lt;span class="k"&gt;[default]&lt;/span&gt;
&lt;span class="na"&gt;aws_access_key_id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;AKIAIH7UMBRMK5L7GT2Q&lt;/span&gt;
&lt;span class="na"&gt;aws_secret_access_key&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;kyLQmrtPwdXrXdxiAOjS1v0zrR06CiEzKKWXIRum&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;If you have this file it is probably so that you can use the credentials with awscli or another command-line utility, or so that you can test a native build of your application that calls AWS in an IDE or when invoked by a build tool such as Maven. We'll explore a specific case as representative of a broad class of vulnerabilities, specifically how a sensitive file could be stolen and how you can make that prohibitively difficult.&lt;/p&gt;
&lt;h3 id="the-problem"&gt;The Problem&lt;/h3&gt;
&lt;p&gt;You are vulnerable to the theft and misuse of your AWS identity if:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;you lose your non-encrypted computer disk where the file is stored, or&lt;/li&gt;
&lt;li&gt;a malicious process designed to steal this credential runs on your computer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This attack is not unique to AWS, of course. Many development and systems administration tools follow the same pattern of issuing an API token as a primary trust factor. Proper handling of these token is too often an afterthought, and we can only surmise that the implications of that carelessness are truly not appreciated by a significant number of software developers. &lt;a href="https://www.cyberscoop.com/twilio-api-eavesdropper-vulnerability/"&gt;The discovery that hundreds of mobile apps had hard-coded API keys for the Twilio platform&lt;/a&gt; is evidence of the same.&lt;/p&gt;
&lt;p&gt;Suppose your employer requires full-disk encryption for all company-provided equipment. In that case a loss of custody of your portable development machine; while inconvenient and frustrating and definitely a security incident; is not a situation worsened by the further implications of a data leak or identity theft. Even with that considerable degree of protection in place, there is another constellation of attack vectors not at all mitigated by full-disk encryption. How many times have your downloaded a utility or app directly from the author or vendor by pasting a &lt;code&gt;curl&lt;/code&gt; or &lt;code&gt;wget&lt;/code&gt; command into your terminal or downloaded an executable or package file? In every case this action implies the delegation of your own privileges on that computer to whomever authored the code that you just executed.&lt;/p&gt;
&lt;p&gt;Your computer doesn't know the difference between you and your logged-in user, and it's that user that owns all of your files and runs all of your processes. That user mostly runs programs written by people other than you. Those programs, running as your user, could read and upload your AWS credentials or any other file for that matter if the source code were maliciously modified to do so. There would be no barrier to that malicious code reading the file, initiating the egressing network connection, nor any tell.&lt;/p&gt;
&lt;p&gt;Importantly, it is possible to dramatically reduce the scope of code that you actually trust in order to operate normally.&lt;/p&gt;
&lt;h3 id="a-solution"&gt;A Solution&lt;/h3&gt;
&lt;p&gt;You can store secrets safely on disk with encryption, decrypt just-in-time to use them normally, and destroy the plaintext.&lt;/p&gt;
&lt;p&gt;Here's a way to do this with PGP that doesn't require you to type a passphrase every time you wish to read the plaintext. With this approach access to the plaintext is controlled by the GnuPG agent and OS login keyring.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This applies to Bourne-compat shells on file-based OSs e.g. BASH and ZSH on MacOS or Linux&lt;/em&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-qd&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials.gpg&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;The plaintext of this file is shellcode like...&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;export&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;AWS_ACCESS_KEY_ID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;AKIAJS7UXB9INMRXLOEA
&lt;span class="nb"&gt;export&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;AWS_SECRET_ACCESS_KEY&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;vXHZEOVxrBtqMkmadkJv0mCeEglrlFA5oBEywSFw
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;
...which makes these values available in the current process environment as well as any child processes' environments. This reduces the surface area for attack by eliminating attack vectors based on filesystem semantics. It is still possible on some operating systems for any process running as &lt;em&gt;you&lt;/em&gt; to read the environment variable with which future child processes are invoked, but those processes are likely to be short-lived and will have unpredictable process IDs which are needed to address the process environment directly. Basically, this makes lifting the credential from your computer difficult.&lt;/p&gt;
&lt;h3 id="do-it-yourself"&gt;Do it Yourself&lt;/h3&gt;
&lt;p&gt;Composing your own encrypted credentials file requires only free, open-source utilities that run on file-based OSs like Linux, MacOS. I'll assume you are using a Bourne-compat shell e.g. BASH, ZSH. You're on your own for API-based OSs like Windows, but I believe this same approach could work there as well. If you get it working and send me the recipe I'll post it here.&lt;/p&gt;
&lt;p&gt;These steps will allow you to continue using the Default Credential Provider chain in AWS SDKs, boto3/awscli, etc...&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install and configure GnuPG command-line interface (CLI) for your OS. I'll assume this will also provide the GnuPG agent which is typically included with modern, trusted GPG packages. &lt;a href="http://blog.ghostinthemachines.com/2015/03/01/how-to-use-gpg-command-line/"&gt;This blog post&lt;/a&gt; looks like a good place to start.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;You will need the user ID (UID) e.g. alice@example.com that you choose in this step in a later step.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use GnuPG CLI &lt;code&gt;gpg&lt;/code&gt; to create an identity aka PGP private key. Github has &lt;a href="https://help.github.com/articles/generating-a-new-gpg-key/"&gt;a helpful post&lt;/a&gt; about this.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Install the AWS CLI which we'll use to verify these steps work. Amazon covers this &lt;a href="https://aws.amazon.com/cli/"&gt;on their web site&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you have more than one credential in &lt;em&gt;~/.aws/credentials&lt;/em&gt; then copy each to a separate file with a meaningful name e.g. &lt;em&gt;~/.aws/credentials-example.com&lt;/em&gt; and perform the next step for each file.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit the plaintext file &lt;em&gt;~/.aws/credentials&lt;/em&gt; so that it resembles the example above. You can manually insert the &lt;code&gt;export&lt;/code&gt; command at the beginning of the two lines and convert the variables names to uppercase or you can run this command which does precisely that in the terminal to prepare the file for encryption.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯&lt;span class="w"&gt; &lt;/span&gt;sed&lt;span class="w"&gt; &lt;/span&gt;-E&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;/^\[.*\]$/d&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;         &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;s/^(\s+)?(aws_(secret_)?access_key(_id)?)(\s+)?=(\s+)?/export \U\2=\E/g&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;         &lt;/span&gt;-i&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Encrypt the credentials file for your user ID (typically the email address you entered when the PGP identity was generated).&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# this command creates a new file with the same filename as the plaintext + suffix &amp;quot;.gpg&amp;quot;&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;-&lt;span class="o"&gt;{&lt;/span&gt;u,r&lt;span class="o"&gt;}&lt;/span&gt;alice@example.com&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prove you can decrypt.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯&lt;span class="w"&gt; &lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-qd&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials.gpg
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;
If this is the first time you have used your PGP identity you may see a GUI popup in your OS prompting for your passphrase. If your OS+GnuPG agent integration allows you may at this time also save the passphrase in your OS keyring. This probably means that your passphrase is chained to your OS login password, and so you should protect that login password with the same measures that are appropriate for your AWS credential.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Source the plaintext into your shell environment and use the credential to authenticate.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-qd&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials.gpg&lt;span class="o"&gt;)&lt;/span&gt;

❯&lt;span class="w"&gt; &lt;/span&gt;aws&lt;span class="w"&gt; &lt;/span&gt;iam&lt;span class="w"&gt; &lt;/span&gt;get-user
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you will be switching between multiple credentials with this method then simply source the plaintext from separate files.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-qd&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials-example.com.gpg&lt;span class="o"&gt;)&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-qd&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials-example.org.gpg&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Now you can delete the plaintext file. If you are feeling less than confident about your future ability to decrypt with your PGP identity then, as a fallback option, consider changing the filemode on the plaintext credentials file so that elevated privileges are required to read it.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;❯&lt;span class="w"&gt; &lt;/span&gt;rm&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials
&lt;span class="c1"&gt;# alternatively, make the file unreadable by unprivileged processes&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;chown&lt;span class="w"&gt; &lt;/span&gt;root&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials
❯&lt;span class="w"&gt; &lt;/span&gt;sudo&lt;span class="w"&gt; &lt;/span&gt;chmod&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0600&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h2 id="shortcuts"&gt;Shortcuts&lt;/h2&gt;
&lt;h3 id="enable-privileges"&gt;Enable Privileges&lt;/h3&gt;
&lt;p&gt;There's no need to memorize the terminal commands. You can save a shellcode "alias" or create a shellcode function to assume any AWS identity for which you have encrypted credentials.&lt;/p&gt;
&lt;p&gt;First, lets look at the most simple case where you have exactly one AWS credential encrypted with the above procedure in &lt;em&gt;~/.aws/credentials.gpg&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# save the following alias in your aliases dotfile or shell runcom file e.g. ~/.bashrc&lt;/span&gt;
&lt;span class="nb"&gt;alias&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;onaws&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;source &amp;lt;(gpg -qd ~/.aws/credentials.gpg)&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# alternatively, you could make this default AWS credential available in every new shell&lt;/span&gt;
&lt;span class="c1"&gt;# environment by including the source command in the shell rc file&lt;/span&gt;
&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-qd&lt;span class="w"&gt; &lt;/span&gt;~/.aws/credentials.gpg&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# source the shell rc file (this happens automatically for your next terminal session)&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;~/.bashrc

&lt;span class="c1"&gt;# then exec the alias to assume the AWS identity&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;onaws
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;If instead you have multiple AWS identities you could use a shellcode function and a file naming convention to quickly assume any one identity.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# save the following function in your aliases dotfile or shell runcom file e.g. ~/.bashrc&lt;/span&gt;
onaws&lt;span class="o"&gt;(){&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;CREDFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;~/.aws/credentials
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-eq&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;CREDFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CREDFILE&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;-&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.gpg
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;CREDFILE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;CREDFILE&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.gpg
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$CREDFILE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-s&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$CREDFILE&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;&lt;span class="o"&gt;(&lt;/span&gt;gpg&lt;span class="w"&gt; &lt;/span&gt;-qd&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$CREDFILE&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;||&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ERROR: &lt;/span&gt;&lt;span class="nv"&gt;$CREDFILE&lt;/span&gt;&lt;span class="s2"&gt; is not readable, or is nonexistent or empty; bye.&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# source the shell rc file (this happens automatically for your next terminal session)&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;~/.bashrc

&lt;span class="c1"&gt;# then exec the function with a positional parameter matching the filename to assume a particular&lt;/span&gt;
&lt;span class="c1"&gt;# AWS identity e.g. stored in ~/.aws/credentials-example.com.gpg&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;onaws&lt;span class="w"&gt; &lt;/span&gt;example.com
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h3 id="disable-privileges"&gt;Disable Privileges&lt;/h3&gt;
&lt;p&gt;You may wish to immediately nullify any credentials and session tokens in memory. You're relatively safe if you end the process where the credentials were sourced, but if for some reason it is preferable for that process to continue running you can explicitly unset the variables with a command.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# save the following alias in your aliases dotfile or shell runcom file e.g. ~/.bashrc&lt;/span&gt;
&lt;span class="nb"&gt;alias&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;noaws&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;unset AWS_ACCESS_KEY \&lt;/span&gt;
&lt;span class="s2"&gt;                   AWS_ACCESS_KEY_ID \&lt;/span&gt;
&lt;span class="s2"&gt;                   AWS_SECRET_ACCESS_KEY \&lt;/span&gt;
&lt;span class="s2"&gt;                   AWS_SECURITY_TOKEN \&lt;/span&gt;
&lt;span class="s2"&gt;                   AWS_SESSION_TOKEN&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# source the shell rc file (this happens automatically for your next terminal session)&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;~/.bashrc

&lt;span class="c1"&gt;# then exec the alias to drop privileges for which ever identity is currently active as well as any&lt;/span&gt;
&lt;span class="c1"&gt;# Simple Token Service sessions you might have obtained via `assume-role`&lt;/span&gt;
❯&lt;span class="w"&gt; &lt;/span&gt;noaws
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h3 id="assume-role"&gt;Assume Role&lt;/h3&gt;
&lt;p&gt;This describes another approach to gaining privileges in AWS and requires that an AWS IAM "role" has already been defined to control access to your resources. This is a global entity in your account that couples an IAM policy to any number of IAM users thereby allowing some action on some resource.&lt;/p&gt;
&lt;p&gt;This is similar but different from using IAM groups to assign the same privileges to multiple users in that it enables granting privileges that span AWS accounts and provides only time-limited, non-interactive session tokens. This is also contrasting to the cumbersome practice of having many IAM user credentials for many AWS accounts.&lt;/p&gt;
&lt;p&gt;It is ideal to grant minimum privileges to a particular role in your own AWS account, and then grant to humans and robots the ability to assume that role with their own IAM user identity. That way they need only one identity regardless of to which AWS account their IAM user belongs, and you can modify the grants for the role in your own AWS account at any time. This also means you never need to know another user's secret access key, and you can still enforce criteria such as multi-factor authentication.&lt;/p&gt;
&lt;p&gt;I've cobbled together &lt;a href="https://github.com/qrkourier/ansible-credstash/blob/master/aws-assume-role.sh"&gt;some additional shellcode functions&lt;/a&gt; (originally to allow Ansible playbooks to assume an IAM role) that implement the following workflow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;source an IAM user identity from an encrypted credentials file&lt;/li&gt;
&lt;li&gt;assume a particular IAM role for the maximum allowed session time (one hour)&lt;ul&gt;
&lt;li&gt;skip assuming role if a session token is already available in a temporary file, and&lt;/li&gt;
&lt;li&gt;prompt for second trust factor (MFA OTP)&lt;/li&gt;
&lt;li&gt;warn if the session token expiry is imminent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;drop privileges&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="related"&gt;Related&lt;/h2&gt;
&lt;p&gt;There are ready-made utilities that also help with properly handling AWS credentials, but that obfuscate the handling of secrets, may place limitations on the way those secrets are used, and are not portable between ubiquitous shell environments. The above solution conserves the trust of yet another piece of software and introduces no limitations to the &lt;code&gt;aws&lt;/code&gt; CLI or the default AWS credential discovery chain employed by most other tools. If you're just looking for a convenient remediation for MacOS, then these others below may be a better fit for you.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;99Designs has &lt;a href="https://99designs.com/tech-blog/blog/2015/10/26/aws-vault/"&gt;a utility called aws-vault&lt;/a&gt; for MacOS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/pda/aws-keychain"&gt;aws-keychain&lt;/a&gt; for MacOS&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AWS publishes &lt;a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html"&gt;best practices for identity access management&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;</content><category term="tech"></category><category term="aws"></category><category term="sysadmin"></category><category term="identity"></category><category term="encryption"></category></entry><entry><title>Virtual Machines as Code</title><link href="https://www.qrk.us/virtual-machines-as-code.html" rel="alternate"></link><published>2023-09-23T21:37:10-04:00</published><updated>2023-09-23T21:37:10-04:00</updated><author><name>Ken</name></author><id>tag:www.qrk.us,2023-09-23:/virtual-machines-as-code.html</id><summary type="html">&lt;p&gt;Optimizing for determinism in virtual machines. This approach can be used to vend the same virtual machine image version in many formats e.g. VHD for Azure, Stack, and Hyper-V; OVA for VMware, VirtualBox; QCOW2 for KVM, and of course RAW.&lt;/p&gt;
&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#tldr"&gt;TL;DR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cloning-vs-code"&gt;Cloning vs Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#choosing-the-upstream-image"&gt;Choosing …&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Optimizing for determinism in virtual machines. This approach can be used to vend the same virtual machine image version in many formats e.g. VHD for Azure, Stack, and Hyper-V; OVA for VMware, VirtualBox; QCOW2 for KVM, and of course RAW.&lt;/p&gt;
&lt;div class="toc"&gt;&lt;span class="toctitle"&gt;Table of contents:&lt;/span&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#tldr"&gt;TL;DR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#cloning-vs-code"&gt;Cloning vs Code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#choosing-the-upstream-image"&gt;Choosing the Upstream Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#configuring-the-image"&gt;Configuring the Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#sealing-the-image"&gt;Sealing the Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#versioning-the-image"&gt;Versioning the Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#releasing-the-image"&gt;Releasing the Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#launching-from-the-image"&gt;Launching from the Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#upgrading-virtual-machines"&gt;Upgrading Virtual Machines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;An overview of the steps using Packer,Ansible, and AWS is given as an example.&lt;/p&gt;
&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Choose a source control manager (SCM) that supports version tagging e.g. Git to house your code and perform the following actions inside the code repository.&lt;/li&gt;
&lt;li&gt;Write a playbook declaring the desired OS configuration. To start, a single Ansible playbook file with several tasks may be sufficient. As your requirements become more complex you’ll employ Ansible roles which are reusable, parameterized configuration.&lt;/li&gt;
&lt;li&gt;Write a Packer template.&lt;/li&gt;
&lt;li&gt;Select the Packer “builder” for the desired VM image format e.g. amazon-ebs.&lt;/li&gt;
&lt;li&gt;Select a trusted upstream image e.g. the Amazon Machine Image (AMI).&lt;/li&gt;
&lt;li&gt;Select a Packer “provisioner” to invoke the configuration playbook e.g. “ansible”.&lt;/li&gt;
&lt;li&gt;Commit the configuration playbook and Packer template to SCM.&lt;/li&gt;
&lt;li&gt;Use a Git tag to “stamp” an immutable version string on the current SCM revision e.g. release-0.1.0.&lt;/li&gt;
&lt;li&gt;Run Packer to “build” the new OS image in the specified format.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="cloning-vs-code"&gt;Cloning vs Code&lt;/h2&gt;
&lt;p&gt;The crucial aim here is a deterministic configuration of a virtual machine from source code. Cloning a disk image reproduces the good, the bad, and the unknown. The starting point for your VM image production pipeline is an upstream, vanilla, verifiable OS image; and the goal is to transform it with code into something useful.&lt;/p&gt;
&lt;h2 id="choosing-the-upstream-image"&gt;Choosing the Upstream Image&lt;/h2&gt;
&lt;p&gt;The obvious choice is the checksum-verified install media from the OS maintainers, but it might make more sense to verify and trust a marketplace vendor, e.g. Rogue Wave Software on Azure, because they provide drivers and tunings for that platform.&lt;/p&gt;
&lt;p&gt;If you require greater assurances or simply want more help with your image you may have more than one stage of upstream image transform that ultimately produces your functional image. One example of a multi-stage approach is to source the upstream image from a trusted vendor, and then to apply an OS hardening Ansible playbook. Alternatively, you could source a hardened OS image from the &lt;a href="https://www.cisecurity.org/services/hardened-virtual-images/"&gt;Center for Internet Security&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Either way, this is a time for diligence in risk management. You’ll want to be certain (enough) that you can verify the chain of custody of the upstream(s) with the rigor that is appropriate for your application.&lt;/p&gt;
&lt;h2 id="configuring-the-image"&gt;Configuring the Image&lt;/h2&gt;
&lt;p&gt;Now that you have a trusted upstream image you’ll set about customizing it for your application. You’ll be glad you used a declarative configuration management system instead of shell scripts, and the fortunate soul that inherits your code too will be grateful. This means that the code that describes the configuration of your OS declares the desired end state e.g. “bind-utils is installed”, and the configuration system takes whatever actions are necessary to effect that state, and reports back whether this was a success with or without any change. In general, this approach offers a more principled approach which brings improved maintainability, strict error handling, debugging tools, and the like. To boot, you’ll probably learn some Python or Ruby along the way. It’s worth it.&lt;/p&gt;
&lt;h2 id="sealing-the-image"&gt;Sealing the Image&lt;/h2&gt;
&lt;p&gt;It’s crucial to scrub and seal the OS before it becomes a reusable image. High-priority items include&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;host SSH identities,&lt;/li&gt;
&lt;li&gt;hardware addresses in network configuration,&lt;/li&gt;
&lt;li&gt;deprovisioning any hypervisor agent e.g. waagent, and&lt;/li&gt;
&lt;li&gt;removing any artifacts of the Packer provisioner(s) e.g. ansible-local requires the playbooks to be uploaded to the prototype VM.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="versioning-the-image"&gt;Versioning the Image&lt;/h2&gt;
&lt;p&gt;Before you run Packer to produce a new OS image, you’ll want to stamp the SCM repo that’s housing all this configuration with an immutable release version string e.g. &lt;code&gt;git tag release-0.1.0&lt;/code&gt;. Ideally, this same string is stamped somewhere in the OS of the resultant image e.g. &lt;code&gt;/etc/release&lt;/code&gt; and is also in the metadata e.g. entity tags of public cloud images like an AMI. Tagging is a feature of Packer’s “amazon-ebs” builder.&lt;/p&gt;
&lt;h2 id="releasing-the-image"&gt;Releasing the Image&lt;/h2&gt;
&lt;p&gt;Most likely, this OS image you’re releasing will eventually become part of a release kit of many versioned components that together compose the full application stack. Importantly, releases are always immutable, and it is at this point that the OS image is “released” to and consumed by the stack. Any further features and fixes will be new release versions. Likewise, you’ll always be able to build an OS image with the current version by checking out the SCM tag on which it was originally built e.g. &lt;code&gt;git checkout release-0.1.0&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="launching-from-the-image"&gt;Launching from the Image&lt;/h2&gt;
&lt;p&gt;The new OS image should be referenced by its version string when launched by the application or a infrastructure-as-code provisioning tool like Terraform. This probably means some kind of lookup table that resolves the version string to the image ID. For example, if you used Packer’s “amazon-ebs” provisioner to assign an AMI tag “ImageVersion=release-0.1.0”, then you could find the AMI with that tag in a particular region with aws CLI.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;aws&lt;span class="w"&gt; &lt;/span&gt;ec2&lt;span class="w"&gt; &lt;/span&gt;describe-images&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;–filters&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;owner-id,Values&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$AWS_ACCOUNT_ID&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;   &lt;/span&gt;–filters&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;Name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;tag:ImageVersion,Values&lt;span class="o"&gt;=&lt;/span&gt;release-0.1.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id="upgrading-virtual-machines"&gt;Upgrading Virtual Machines&lt;/h2&gt;
&lt;p&gt;You’ll have to judge whether your application is best served by an in-place upgrade or turn-and-burn. The advantages of latter are enabled by a stack architecture that abstracts away persistence from the purview of the VM. If you can see a path forward to that end, then “Go West”. If you are forced to manage in-place upgrades then an aggressive always-latest-stable kind of strategy works best, and tools like Salt Stack are your friends.&lt;/p&gt;</content><category term="tech"></category><category term="packer"></category><category term="ansible"></category><category term="terraform"></category><category term="devops"></category><category term="iaas"></category></entry></feed>